{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e0a6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using h5py to unpack the archived file which holds the information for our \n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d016bb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in base dir: [('Test Data', <HDF5 group \"/Test Data\" (2 members)>), ('Train Data', <HDF5 group \"/Train Data\" (2 members)>)]\n",
      "items in group 1: [('x_train', <HDF5 dataset \"x_train\": shape (62870, 64, 64), type \"|u1\">), ('y_train', <HDF5 dataset \"y_train\": shape (62870,), type \"<i8\">)]\n",
      "items in group 2: [('x_test', <HDF5 dataset \"x_test\": shape (28080, 64, 64), type \"|u1\">), ('y_test', <HDF5 dataset \"y_test\": shape (28080,), type \"<i8\">)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55000, 64, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's extract our training, test and validation data\n",
    "#method seen in [1] p21\n",
    "with h5py.File('../HDF5/hdf5_uTHCD_compressed.h5', 'r') as hdf:\n",
    "    base_items = list(hdf.items())\n",
    "    print(f'Items in base dir: {base_items}')\n",
    "    G1 = hdf.get('Train Data')\n",
    "    G1_items = list(G1.items())\n",
    "    print(f'items in group 1: {G1_items}')\n",
    "    \n",
    "    G2 = hdf.get('Test Data')\n",
    "    G2_items = list(G2.items())\n",
    "    print(f'items in group 2: {G2_items}')\n",
    "    \n",
    "    x_train = np.array(G1.get('x_train'))\n",
    "    y_train = np.array(G1.get('y_train'))\n",
    "    \n",
    "    x_test = np.array(G2.get('x_test'))\n",
    "    y_test = np.array(G2.get('y_test'))\n",
    "    \n",
    "    x_val = x_train[-7870:,:,:]\n",
    "    y_val = y_train[-7870:]\n",
    "    \n",
    "    x_train = x_train[:-7870,:,:]\n",
    "    y_train = y_train[:-7870]\n",
    "    \n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cacd1e8",
   "metadata": {},
   "source": [
    "Now that we have the data, we actually need to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de9d34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import pandas as pd\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3437027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's try a SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae434578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7870, 64, 64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11f35fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7870, 64, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It's important to note here we are using very basic parameters and the simple linear kernel\n",
    "svc = svm.SVC(gamma=0.001,kernel='linear', C = 100)\n",
    "\n",
    "#reshaping the data to work for SVC while maintaining images. Likely poor optimization\n",
    "x_train_svc = x_train.reshape(55000,-1)\n",
    "x_test_svc = x_test.reshape(28080, -1)\n",
    "x_val_svc = x_val.reshape(7870,-1)\n",
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f726084f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, gamma=0.001, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, gamma=0.001, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, gamma=0.001, kernel='linear')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we're gonna train on only 1000 samples until we figure out complexity issues\n",
    "SAMPLE_SIZE = 1000\n",
    "svc.fit(x_train_svc[:SAMPLE_SIZE],y_train[:SAMPLE_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5013198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "predictions = svc.predict(x_test_svc[:SAMPLE_SIZE])\n",
    "print(\"end\")\n",
    "(predictions, y_test[:SAMPLE_SIZE])\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for pred, expect in zip(predictions,y_test[:SAMPLE_SIZE]):\n",
    "    if pred == expect:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33cf749f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.448"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some analysis of our model's performance with the linear kernel\n",
    "#accuracy:\n",
    "correct/SAMPLE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7ff00ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's see how it does on the validation data\n",
    "predictions = svc.predict(x_val_svc[:SAMPLE_SIZE])\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for pred, expect in zip(predictions,y_val[:SAMPLE_SIZE]):\n",
    "    if pred == expect:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cad1dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.518"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/SAMPLE_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56ecdd4",
   "metadata": {},
   "source": [
    "Likely slightly more accurate due to the validation data being closer in size to SAMPLE_SIZE than testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "183c47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11bc4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions to compute f1 score later\n",
    "#taken from [3]\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e60864d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 62, 62, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 31, 31, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              6423552   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 156)               80028     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7037948 (26.85 MB)\n",
      "Trainable params: 7037948 (26.85 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#set up and build the initial model of 2D convolutional layers and MaxPooling\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(64,64,1)))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "#will now flatten conv layers and add 3 dense layers of size 1024 and 512\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(156)) #156 distinct char classes per [1] p.3\n",
    "model.summary() #to output a depiction of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a14aa94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 10:42:13.402094: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 225280000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 233s 135ms/step - loss: 0.1905 - accuracy: 0.9434 - f1_m: 1.3109 - precision_m: 1.0722 - recall_m: 1.7390 - val_loss: 0.7892 - val_accuracy: 0.8201 - val_f1_m: 1.3469 - val_precision_m: 1.1062 - val_recall_m: 1.7363\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 232s 135ms/step - loss: 0.1299 - accuracy: 0.9617 - f1_m: 1.2234 - precision_m: 1.0559 - recall_m: 1.4640 - val_loss: 0.7960 - val_accuracy: 0.8220 - val_f1_m: 1.2124 - val_precision_m: 1.0927 - val_recall_m: 1.3711\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 233s 135ms/step - loss: 0.1100 - accuracy: 0.9687 - f1_m: 1.1735 - precision_m: 1.0477 - recall_m: 1.3409 - val_loss: 0.9093 - val_accuracy: 0.8282 - val_f1_m: 1.2075 - val_precision_m: 1.0681 - val_recall_m: 1.4012\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 232s 135ms/step - loss: 0.0972 - accuracy: 0.9715 - f1_m: 1.1495 - precision_m: 1.0391 - recall_m: 1.2927 - val_loss: 1.0390 - val_accuracy: 0.8113 - val_f1_m: 1.2512 - val_precision_m: 1.0717 - val_recall_m: 1.5147\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 233s 135ms/step - loss: 0.0892 - accuracy: 0.9746 - f1_m: 1.1294 - precision_m: 1.0349 - recall_m: 1.2487 - val_loss: 1.1357 - val_accuracy: 0.8031 - val_f1_m: 1.1621 - val_precision_m: 1.0709 - val_recall_m: 1.2790\n"
     ]
    }
   ],
   "source": [
    "#compile the model using SparseCategoricalCrossentropy (see [2]) \n",
    "#here we only use 4 epochs to train\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy',f1_m,precision_m,recall_m]) \n",
    "res = model.fit(x_train,y_train, epochs=5, validation_data=(x_test,y_test)) #fit the training and test data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad946072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878/878 [==============================] - 18s 21ms/step - loss: 1.1357 - accuracy: 0.8031 - f1_m: 1.1621 - precision_m: 1.0709 - recall_m: 1.2790\n",
      "loss: 1.1357309818267822\n",
      "acc: 0.8030982613563538\n",
      "f1: 1.1620622873306274\n",
      "precision: 1.0709322690963745\n",
      "recall: 1.2789952754974365\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_precision, test_recall = model.evaluate(x_test, y_test)\n",
    "print(f'loss: {test_loss}\\nacc: {test_acc}\\nf1: {test_f1}\\nprecision: {test_precision}\\nrecall: {test_recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbe63f39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 5s 21ms/step - loss: 0.7097 - accuracy: 0.8709 - f1_m: 1.1531 - precision_m: 1.0556 - recall_m: 1.2780\n",
      "loss: 0.7097020149230957\n",
      "acc: 0.8709021806716919\n",
      "f1: 1.1530578136444092\n",
      "precision: 1.0556143522262573\n",
      "recall: 1.278039574623108\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc, val_f1, val_precision, val_recall = model.evaluate(x_val,y_val)\n",
    "print(f'loss: {val_loss}\\nacc: {val_acc}\\nf1: {val_f1}\\nprecision: {val_precision}\\nrecall: {val_recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ac8af8",
   "metadata": {},
   "source": [
    "REFERENCES:\n",
    "[1]: N. Shaffi and F. Hajamohideen, \"uTHCD: A New Benchmarking for Tamil Handwritten OCR,\" in IEEE Access, vol. 9, pp. 101469-101493, 2021, doi: 10.1109/ACCESS.2021.3096823.\n",
    "[2]: https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy \n",
    "'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3d89bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
